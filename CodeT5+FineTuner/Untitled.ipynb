{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1316023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /opt/conda/envs/ctp/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda113.so\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.0\n",
      "CUDA SETUP: Detected CUDA version 113\n",
      "CUDA SETUP: Loading binary /opt/conda/envs/ctp/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/ctp/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /opt/conda/envs/ctp did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-07 12:33:56,900] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c33306dddb55457aa7d2aa5c1449812c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6785645484924316\n",
      "\"I'm converting an iPython notebook to a python script, just trying to output the results of a couple Seaborn plots as png files. Code:\n",
      "import seaborn as sns \n",
      "sns.set_style(\"whitegrid\") \n",
      "ax = sns.barplot(x=range(1,11), y=[ (x/nrows)*100 for x in addr_pop ], palette=\"Blues_d\")\n",
      "ax.savefig(\"html/addr_depth.png\")\n",
      "Don't worry about the variables, they're populated as expected, and I get a great-looking chart in iPyNB. Running the code within a script, however, yields RuntimeError: Invalid DISPLAY variable.\n",
      "Following another thread, I modified the code, putting this at the top of the script:\n",
      "import matplotlib\n",
      "matplotlib.use('Agg')\n",
      "And tried again. This time, it doesn't seem like the savefig() method is available for the plot at all:\n",
      "AttributeError: 'AxesSubplot' object has no attribute'savefig'\n",
      " All the results searching out this error are related to pandas and a plot that is already being displayed. I'm just trying to get Seaborn to output the fig to a file, ideally without displaying it at all.\n",
      "any help is appreciated.\n",
      "\"\"\"\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import torch\n",
    "#from transformers import BitsAndBytesConfig\n",
    "import time\n",
    "\n",
    "checkpoint = \"Salesforce/instructcodet5p-16b\"\n",
    "device = \"cuda\" # for GPU usage or \"cpu\" for CPU usage\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint,\n",
    "                                              torch_dtype=torch.float16,\n",
    "                                              low_cpu_mem_usage=True,\n",
    "                                              trust_remote_code=True).to(device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f01dab9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(ip):\n",
    "    \n",
    "    #start_time= time.time()\n",
    "    # print(start_time)\n",
    "    encoding = tokenizer(ip, return_tensors=\"pt\").to(device)\n",
    "    encoding['decoder_input_ids'] = encoding['input_ids'].clone()\n",
    "    outputs = model.generate(**encoding, max_length=1024)\n",
    "    stop_time=time.time()\n",
    "    duration =stop_time - start_time\n",
    "    print(duration)\n",
    "    op=tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    print(op[len(ip):])\n",
    "    return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e261eb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "520.5269019603729\n",
      "\n",
      "    \"\"\"\n",
      "    def __init__(self, operator, operand, cut_off_cycle=False):\n",
      "        self.operator = operator\n",
      "        self.operand = operand\n",
      "        self.cut_off_cycle = cut_off_cycle\n",
      "        self.counter = 0\n",
      "\n",
      "    def __iter__(self):\n",
      "        return self\n",
      "\n",
      "    def __next__(self):\n",
      "        if self.counter == 0:\n",
      "            self.counter += 1\n",
      "            return self.operator\n",
      "        elif self.counter == 1:\n",
      "            self.counter += 1\n",
      "            return self.operand\n",
      "        elif self.counter == 2:\n",
      "            self.counter += 1\n",
      "            return self.operator\n",
      "        elif self.counter == 3:\n",
      "            self.counter += 1\n",
      "            return self.operand\n",
      "        elif self.counter == 4:\n",
      "            self.counter += 1\n",
      "            return self.operator\n",
      "        elif self.counter == 5:\n",
      "            self.counter += 1\n",
      "            return self.operand\n",
      "        elif self.counter == 6:\n",
      "            self.counter += 1\n",
      "            return self.operator\n",
      "        elif self.counter == 7:\n",
      "            self.counter += 1\n",
      "            return self.operand\n",
      "        elif self.counter == 8:\n",
      "            self.counter += 1\n",
      "            return self.operator\n",
      "        elif self.counter == 9:\n",
      "            self.counter += 1\n",
      "            return self.operand\n",
      "        elif self.counter == 10:\n",
      "            self.counter += 1\n",
      "            return self.operator\n",
      "        elif self.counter == 11:\n",
      "            self.counter += 1\n",
      "            return self.operand\n",
      "        elif self.counter == 12:\n",
      "            self.counter += 1\n",
      "            return self.operator\n",
      "        elif self.counter == 13:\n",
      "            self.counter += 1\n",
      "            return self.operand\n",
      "        elif self.counter == 14:\n",
      "            self.counter += 1\n",
      "            return self.operator\n",
      "        elif self.counter == 15:\n",
      "            self.counter += 1\n",
      "            return self.operand\n",
      "        elif self.counter == 16:\n",
      "            self.counter += 1\n",
      "            return self.operator\n",
      "        elif self.counter == 17:\n",
      "            self.counter += 1\n",
      "            return self.operand\n",
      "        elif self.counter == 18:\n",
      "            self.counter += 1\n",
      "            return self.operator\n",
      "        elif self.counter == 19:\n",
      "            self.counter += 1\n",
      "            return self.operand\n",
      "        elif self.counter == 20:\n",
      "            self.counter += 1\n",
      "            return self.operator\n",
      "        elif self.counter == 21:\n",
      "            self.counter += 1\n",
      "            return self.operand\n",
      "        elif self.counter == 22:\n",
      "            self.counter += 1\n",
      "            return self.operator\n",
      "        elif self.counter == 23:\n",
      "            self.counter += 1\n",
      "            return self.operand\n",
      "        elif self.counter == 24:\n",
      "            self.counter += 1\n",
      "            return self.operator\n",
      "        elif self.counter == 25:\n",
      "            self.counter += 1\n",
      "            return self.operand\n",
      "        elif self.counter == 26:\n",
      "            self.counter += 1\n",
      "            return self.operator\n",
      "        elif self.counter == 27:\n",
      "            self.counter += 1\n",
      "            return self.operand\n",
      "        elif self.counter == 28:\n",
      "            self.counter += 1\n",
      "            return self.operator\n",
      "        elif self.counter == 29:\n",
      "            self.counter += 1\n",
      "            return self.operand\n",
      "        elif self.counter == 30:\n",
      "            self.counter += 1\n",
      "            return self.operator\n",
      "        elif self.counter == 31:\n",
      "            self.counter += 1\n",
      "            return self.operand\n",
      "        elif self.counter == 32:\n",
      "            self.counter += 1\n",
      "            return self.operator\n",
      "        elif self.counter == 33:\n",
      "            self.counter += 1\n",
      "            return self.operand\n",
      "        elif self.counter == 34:\n",
      "            self.counter += 1\n",
      "            return self.operator\n",
      "        elif self.counter == 35:\n",
      "            self.counter += 1\n",
      "            return self.operand\n",
      "        elif self.counter == 36:\n",
      "            self.counter += 1\n",
      "            return self.operator\n",
      "        elif self.counter == 37:\n",
      "            self.counter += 1\n",
      "            return self.operand\n",
      "        elif self.counter == 38:\n",
      "            self\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\"How to Implement using recursion and cut-off cycle of the counter (like `for i: = 1 downto N do <operator>`)? \\n    \"\"\"\\n    def __init__(self, operator, operand, cut_off_cycle=False):\\n        self.operator = operator\\n        self.operand = operand\\n        self.cut_off_cycle = cut_off_cycle\\n        self.counter = 0\\n\\n    def __iter__(self):\\n        return self\\n\\n    def __next__(self):\\n        if self.counter == 0:\\n            self.counter += 1\\n            return self.operator\\n        elif self.counter == 1:\\n            self.counter += 1\\n            return self.operand\\n        elif self.counter == 2:\\n            self.counter += 1\\n            return self.operator\\n        elif self.counter == 3:\\n            self.counter += 1\\n            return self.operand\\n        elif self.counter == 4:\\n            self.counter += 1\\n            return self.operator\\n        elif self.counter == 5:\\n            self.counter += 1\\n            return self.operand\\n        elif self.counter == 6:\\n            self.counter += 1\\n            return self.operator\\n        elif self.counter == 7:\\n            self.counter += 1\\n            return self.operand\\n        elif self.counter == 8:\\n            self.counter += 1\\n            return self.operator\\n        elif self.counter == 9:\\n            self.counter += 1\\n            return self.operand\\n        elif self.counter == 10:\\n            self.counter += 1\\n            return self.operator\\n        elif self.counter == 11:\\n            self.counter += 1\\n            return self.operand\\n        elif self.counter == 12:\\n            self.counter += 1\\n            return self.operator\\n        elif self.counter == 13:\\n            self.counter += 1\\n            return self.operand\\n        elif self.counter == 14:\\n            self.counter += 1\\n            return self.operator\\n        elif self.counter == 15:\\n            self.counter += 1\\n            return self.operand\\n        elif self.counter == 16:\\n            self.counter += 1\\n            return self.operator\\n        elif self.counter == 17:\\n            self.counter += 1\\n            return self.operand\\n        elif self.counter == 18:\\n            self.counter += 1\\n            return self.operator\\n        elif self.counter == 19:\\n            self.counter += 1\\n            return self.operand\\n        elif self.counter == 20:\\n            self.counter += 1\\n            return self.operator\\n        elif self.counter == 21:\\n            self.counter += 1\\n            return self.operand\\n        elif self.counter == 22:\\n            self.counter += 1\\n            return self.operator\\n        elif self.counter == 23:\\n            self.counter += 1\\n            return self.operand\\n        elif self.counter == 24:\\n            self.counter += 1\\n            return self.operator\\n        elif self.counter == 25:\\n            self.counter += 1\\n            return self.operand\\n        elif self.counter == 26:\\n            self.counter += 1\\n            return self.operator\\n        elif self.counter == 27:\\n            self.counter += 1\\n            return self.operand\\n        elif self.counter == 28:\\n            self.counter += 1\\n            return self.operator\\n        elif self.counter == 29:\\n            self.counter += 1\\n            return self.operand\\n        elif self.counter == 30:\\n            self.counter += 1\\n            return self.operator\\n        elif self.counter == 31:\\n            self.counter += 1\\n            return self.operand\\n        elif self.counter == 32:\\n            self.counter += 1\\n            return self.operator\\n        elif self.counter == 33:\\n            self.counter += 1\\n            return self.operand\\n        elif self.counter == 34:\\n            self.counter += 1\\n            return self.operator\\n        elif self.counter == 35:\\n            self.counter += 1\\n            return self.operand\\n        elif self.counter == 36:\\n            self.counter += 1\\n            return self.operator\\n        elif self.counter == 37:\\n            self.counter += 1\\n            return self.operand\\n        elif self.counter == 38:\\n            self'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference(\"\"\"How to Implement using recursion and cut-off cycle of the counter (like `for i: = 1 downto N do <operator>`) ? \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b57a90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "I want to drop a specific row from the dataframe. Provide me all the possible ways to achive the task. The dataframe is stored\n",
      "in variable df \n",
      "\n",
      "### Response:\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import torch\n",
    "from transformers import BitsAndBytesConfig\n",
    "import time, os\n",
    "\n",
    "load = \"Salesforce/codet5p-16b\"\n",
    "device = \"cuda\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"Below is an instruction that describes a task, paired with an input that provides further context. \"\n",
    "        \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "        \"### Instruction:\\n{instruction}\\n\\n### Input:\\n{input}\\n\\n### Response:\"\n",
    "    ),\n",
    "    \"prompt_no_input\": (\n",
    "        \"Below is an instruction that describes a task. \"\n",
    "        \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "        \"### Instruction:\\n{instruction}\\n\\n### Response:\"\n",
    "    ),\n",
    "}\n",
    "max_len = 512\n",
    "\n",
    "import re\n",
    "def truncate(completion):\n",
    "    import re\n",
    "    \n",
    "    def find_re(string, pattern, start_pos):\n",
    "        m = pattern.search(string, start_pos)\n",
    "        return m.start() if m else -1\n",
    "\n",
    "    terminals = [re.compile(r, re.MULTILINE) for r in [re.escape('<|end|>'),\"^'''\", '^\"\"\"', '\\n\\n\\n']]\n",
    "\n",
    "    prints = list(re.finditer('^print', completion, re.MULTILINE))\n",
    "    if len(prints) > 1:\n",
    "        completion = completion[:prints[1].start()]\n",
    "\n",
    "    defs = list(re.finditer('^def', completion, re.MULTILINE))\n",
    "    if len(defs) > 1:\n",
    "        completion = completion[:defs[1].start()]\n",
    "\n",
    "    start_pos = 0\n",
    "\n",
    "    terminals_pos = [pos for pos in [find_re(completion, terminal, start_pos) for terminal in terminals] if pos != -1]\n",
    "    if len(terminals_pos) > 0:\n",
    "        return completion[:min(terminals_pos)]\n",
    "    else:\n",
    "        return completion  \n",
    "\n",
    "def preprocess_test_ip(test_ip):\n",
    "    prompt_input, prompt_no_input = PROMPT_DICT[\"prompt_input\"], PROMPT_DICT[\"prompt_no_input\"]\n",
    "    instruct, inp = test_ip[\"instruction\"], test_ip[\"input\"]\n",
    "    if inp!=\"\":\n",
    "        source = prompt_input.format_map({'instruction': instruct, 'input': inp})\n",
    "    else:\n",
    "        source = prompt_no_input.format_map({'instruction': instruct})\n",
    "    return source\n",
    "\n",
    "test_ip = {\"instruction\":\"\"\"\n",
    "I want to drop a specific row from the dataframe. Provide me all the possible ways to achive the task. The dataframe is stored\n",
    "in variable df \"\"\", \"input\":\"\"}\n",
    "\n",
    "fmt_test_ip = preprocess_test_ip(test_ip)\n",
    "print(fmt_test_ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3025790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /opt/conda/envs/ctp/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda113.so\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.0\n",
      "CUDA SETUP: Detected CUDA version 113\n",
      "CUDA SETUP: Loading binary /opt/conda/envs/ctp/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/ctp/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /opt/conda/envs/ctp did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-07 18:11:11,338] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "add5ef159f9e47409b1e95cbfb733347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(load)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(load,\n",
    "                                              torch_dtype=torch.float16,\n",
    "                                              low_cpu_mem_usage=True,\n",
    "                                              trust_remote_code=True,\n",
    "                                              quantization_config=bnb_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e51fc4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inf_without_ft(test_ip):\n",
    "    start_time= time.time()\n",
    "    fmt_test_ip = preprocess_test_ip(test_ip)\n",
    "    encoding = tokenizer(fmt_test_ip, return_tensors=\"pt\").to(device)\n",
    "    encoding['decoder_input_ids'] = encoding['input_ids'].clone()\n",
    "    outputs = model.generate(**encoding, max_length=512)\n",
    "    resp = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    stop_time=time.time()\n",
    "    duration =stop_time - start_time\n",
    "    return resp, duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1866ef6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "resp, duration =inf_without_ft(test_ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62519f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117.55983567237854 s\n",
      ":\n",
      "\n",
      "I want to drop a specific row from the dataframe. Provide me all the possible ways to achive the task. The dataframe is stored\n",
      "in variable df \n",
      "\n",
      "df.drop(df.index[0])\n",
      "\n",
      "df.drop(df.index[0], inplace=True)\n",
      "\n",
      "df.drop(df.index[0], inplace=True, axis=1)\n",
      "\n",
      "df.drop(df.index[0], inplace=True, axis=1)\n",
      "\n",
      "df.drop(df.index[0], inplace=True, columns=['col1', 'col2'])\n",
      "\n",
      "df.drop(df.index[0], inplace=True, columns=['col1', 'col2'])\n",
      "\n",
      "df.drop(df.index[0], inplace=True, columns=['col1', 'col2'], axis=1)\n",
      "\n",
      "df.drop(df.index[0], inplace=True, columns=['col1', 'col2'], axis=1)\n",
      "\n",
      "df.drop(df.index[0], inplace=True, columns=['col1', 'col2'], axis=1, level=0)\n",
      "\n",
      "df.drop(df.index[0], inplace=True, columns=['col1', 'col2'], axis=1, level=0)\n",
      "\n",
      "df.drop(df.index[0], inplace=True, columns=['col1', 'col2'], axis=1, level=0, inplace=True)\n",
      "\n",
      "df.drop(df.index[0], inplace=True, columns=['col1', 'col2'], axis=1, level=0, inplace=True, errors='ignore')\n",
      "\n",
      "df.drop(df.index[0], inplace=True, columns=['col1', 'col2'], axis=1, level=0, errors='ignore')\n",
      "\n",
      "df.drop(df.index[0], inplace=True, columns=['\n"
     ]
    }
   ],
   "source": [
    "print(str(duration)+' s')\n",
    "print(resp[len(fmt_test_ip):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a13bac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Salesforce/codet5p-16b requires to execute some code in that repo, you can inspect the content of the repository at https://hf.co/Salesforce/codet5p-16b. You can dismiss this prompt by passing `trust_remote_code=True`.\n",
      "Do you accept? [y/N] y\n",
      "Loading Salesforce/codet5p-16b requires to execute some code in that repo, you can inspect the content of the repository at https://hf.co/Salesforce/codet5p-16b. You can dismiss this prompt by passing `trust_remote_code=True`.\n",
      "Do you accept? [y/N] y\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26488aadd2214a63b68dd6ff08b1fecf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from peft import PeftModel\n",
    "from transformers import BitsAndBytesConfig\n",
    "import os\n",
    "\n",
    "\n",
    "save_dir=\"saved_models/instruct_set\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "final_checkpoint_dir = os.path.join(save_dir, \"final_checkpoint\")\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "max_len = 512\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    load,\n",
    "    return_dict=True,\n",
    "    low_cpu_mem_usage=True,\n",
    "    quantization_config=bnb_config\n",
    ")\n",
    "ft_model = PeftModel.from_pretrained(base_model, final_checkpoint_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(final_checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61d9834f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inf_with_ft(test_ip):\n",
    "    start_time= time.time()\n",
    "    fmt_test_ip = preprocess_test_ip(test_ip)\n",
    "    encoding = tokenizer(fmt_test_ip, return_tensors=\"pt\").to(device)\n",
    "    encoding['decoder_input_ids'] = encoding['input_ids'].clone()\n",
    "    outputs = ft_model.generate(**encoding, max_length=512)\n",
    "    resp = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    stop_time=time.time()\n",
    "    duration =stop_time - start_time\n",
    "    return resp, duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0e4289b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "resp, duration =inf_with_ft(test_ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b33d7ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119.44236135482788 s\n",
      ":You can drop a specific row by using the drop() function. Here's an example:\n",
      "\n",
      "```\n",
      "df = pd.DataFrame({'A': [1, 2, 3, 4],\n",
      "                   'B': [5, 6, 7, 8],\n",
      "                   'C': [9, 10, 11, 12]})\n",
      "\n",
      "# Drop the first row\n",
      "df.drop(0)\n",
      "\n",
      "# Drop the first two rows\n",
      "df.drop([0, 1])\n",
      "\n",
      "# Drop the first row and the second row\n",
      "df.drop([0, 1], axis=0)\n",
      "\n",
      "# Drop the first two rows and the second row\n",
      "df.drop([0, 1, 2], axis=0)\n",
      "```\n",
      "\n",
      "You can also use the dropna() function to drop rows with missing values. Here's an example:\n",
      "\n",
      "```\n",
      "df = pd.DataFrame({'A': [1, 2, 3, 4],\n",
      "                   'B': [5, 6, 7, np.nan],\n",
      "                   'C': [9, 10, 11, 12]})\n",
      "\n",
      "# Drop the rows with missing values\n",
      "df.dropna()\n",
      "\n",
      "# Drop the rows with missing values and the first row\n",
      "df.dropna(axis=0)\n",
      "\n",
      "# Drop the rows with missing values and the first two rows\n",
      "df.dropna(axis=0, how='any')\n",
      "\n",
      "# Drop the rows with missing values and the first two rows and the second row\n",
      "df.dropna(axis=0, how='any', thresh=2)\n",
      "```\n",
      "\n",
      "You can also use the drop_duplicates() function to drop duplicate rows. Here's an example:\n",
      "\n",
      "```\n",
      "df = pd.DataFrame({'A': [1, 2, 3, 4],\n",
      "                   'B': [5, 6, 7, 8],\n",
      "                   'C': [9, 10, 11, 12]})\n",
      "\n",
      "# Drop the first row\n",
      "df.drop_duplicates(subset='A')\n",
      "\n",
      "# Drop the\n"
     ]
    }
   ],
   "source": [
    "print(str(duration)+' s')\n",
    "print(resp[len(fmt_test_ip):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9652b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "from datasets import Dataset  \n",
    "from huggingface_hub import HfApi  \n",
    "from getpass import getpass  \n",
    "  \n",
    "# Load the CSV file into a pandas dataframe  \n",
    "df = pd.read_csv(r\"/home/unnati/batchsize_experiments/cleaned_dataframe2.csv\", names=['question', 'answer'])  \n",
    "  \n",
    "# Convert the pandas dataframe into a Hugging Face dataset  \n",
    "dataset = Dataset.from_pandas(df)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed0c6f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['question', 'answer'],\n",
      "    num_rows: 197\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82bd2e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.rename_column('question', 'instruction') \n",
    "dataset = dataset.rename_column('answer', 'output') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd055588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['instruction', 'output'],\n",
      "    num_rows: 251\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96dd60a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/197 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.save_to_disk(r'/home/unnati/batchsize_experiments/pandu') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6e4f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
